{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "## Haga un análisis exploratorio de los datos para entenderlos mejor, documente todos los análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos en un DataFrame de pandas\n",
    "df = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras 5 filas de los datos\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mostrar información básica sobre los datos\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pixel0   pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7  \\\n",
      "count  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0  28000.0   \n",
      "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "        pixel8   pixel9  ...      pixel774      pixel775      pixel776  \\\n",
      "count  28000.0  28000.0  ...  28000.000000  28000.000000  28000.000000   \n",
      "mean       0.0      0.0  ...      0.164607      0.073214      0.028036   \n",
      "std        0.0      0.0  ...      5.473293      3.616811      1.813602   \n",
      "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
      "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
      "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
      "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
      "max        0.0      0.0  ...    253.000000    254.000000    193.000000   \n",
      "\n",
      "           pixel777      pixel778  pixel779  pixel780  pixel781  pixel782  \\\n",
      "count  28000.000000  28000.000000   28000.0   28000.0   28000.0   28000.0   \n",
      "mean       0.011250      0.006536       0.0       0.0       0.0       0.0   \n",
      "std        1.205211      0.807475       0.0       0.0       0.0       0.0   \n",
      "min        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
      "25%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
      "50%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
      "75%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
      "max      187.000000    119.000000       0.0       0.0       0.0       0.0   \n",
      "\n",
      "       pixel783  \n",
      "count   28000.0  \n",
      "mean        0.0  \n",
      "std         0.0  \n",
      "min         0.0  \n",
      "25%         0.0  \n",
      "50%         0.0  \n",
      "75%         0.0  \n",
      "max         0.0  \n",
      "\n",
      "[8 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar estadísticas básicas sobre los datos\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haga un modelo de redes neuronales simple, determine la efectividad del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.2926 - accuracy: 0.9172\n",
      "Epoch 2/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.1298 - accuracy: 0.9626\n",
      "Epoch 3/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0896 - accuracy: 0.9727\n",
      "Epoch 4/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0676 - accuracy: 0.9801\n",
      "Epoch 5/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0514 - accuracy: 0.9848\n",
      "Epoch 6/10\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0392 - accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0312 - accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0240 - accuracy: 0.9929\n",
      "Epoch 9/10\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0199 - accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0165 - accuracy: 0.9948\n",
      "1313/1313 [==============================] - 1s 1ms/step - loss: 0.0131 - accuracy: 0.9962\n",
      "Precisión: 99.62%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "# Normalizar los valores de los píxeles al rango [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "# Codificar las etiquetas en un formato one-hot\n",
    "y_one_hot = to_categorical(y)\n",
    "\n",
    "# Crear la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X, y_one_hot, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluar la precisión del modelo en los datos de entrenamiento\n",
    "loss, accuracy = model.evaluate(X, y_one_hot)\n",
    "print(f\"Precisión: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haga un modelo de Deep learning, determine la efectividad del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 1.5376 - accuracy: 0.7421\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4732 - accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3310 - accuracy: 0.9234\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2503 - accuracy: 0.9379\n",
      "Epoch 5/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1989 - accuracy: 0.9499\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.1691 - accuracy: 0.9570\n",
      "Epoch 7/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1425 - accuracy: 0.9624\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1222 - accuracy: 0.9671\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1103 - accuracy: 0.9710\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 2s 1ms/step - loss: 0.1034 - accuracy: 0.9712\n",
      "263/263 [==============================] - 0s 823us/step\n",
      "Accuracy: 95.6310\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_class, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haga un modelo con cualquier otro algoritmo que el grupo seleccione, determine la efectividad del modelo\n",
    "### Elegimos CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocesar los datos\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "# Crear el modelo\n",
    "model = models.Sequential()\n",
    "\n",
    "# Agregar capas convolucionales y de agrupación\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Agregar capas densamente conectadas\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0214 - accuracy: 0.9936\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0160 - accuracy: 0.9945\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0111 - accuracy: 0.9964\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.0117 - accuracy: 0.9960\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0088 - accuracy: 0.9969\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9926\n",
      "Test accuracy: 99.26000237464905\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
